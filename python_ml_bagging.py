# -*- coding: utf-8 -*-
"""
Created on Tue Nov 14 11:02:17 2023

@author: Marko
"""

# Bagging

# Укладання в мішки
# Такі методи, як Дерева рішень, можуть бути схильні до переобладнання навчального набору, що може призвести до неправильних прогнозів щодо нових даних.
# Bootstrap Aggregation (bagging) — це метод ансамблювання, який намагається вирішити проблеми з переобладнанням для класифікації або регресії. Bagging має на меті покращити точність і продуктивність алгоритмів машинного навчання. Він робить це, беручи випадкові підмножини вихідного набору даних із заміною та підбираючи або класифікатор (для класифікації), або регресор (для регресії) до кожної підмножини. Прогнози для кожної підмножини потім агрегуються більшістю голосів для класифікації або усереднення для регресії, що підвищує точність прогнозу.

# Щоб побачити, як пакетування може покращити продуктивність моделі, ми повинні почати з оцінки того, як базовий класифікатор працює з набором даних. 
# Ми намагатимемося ідентифікувати різні класи вин у наборі даних Sklearn про вина.

# Почнемо з імпорту необхідних модулів.
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier

# Далі нам потрібно завантажити дані та зберегти їх у X (вхідні функції) та y (ціль). Параметр as_frame має значення True, тому ми не втрачаємо назви функцій під час завантаження даних. ( sklearnверсія старша за 0.23 має пропускати as_frameаргумент, оскільки він не підтримується)
data = datasets.load_wine(as_frame = True)

X = data.data
y = data.target
# Щоб правильно оцінити нашу модель на невидимих ​​даних, нам потрібно розділити X і y на набори тренувань і тестів. 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)
# Отримавши підготовлені дані, тепер ми можемо створити екземпляр базового класифікатора та адаптувати його до навчальних даних.
dtree = DecisionTreeClassifier(random_state = 22)
dtree.fit(X_train,y_train)
# Тепер ми можемо передбачити клас вина невидимого тестового набору та оцінити продуктивність моделі.
y_pred = dtree.predict(X_test)

print("Train data accuracy:",accuracy_score(y_true = y_train, y_pred = dtree.predict(X_train)))
print("Test data accuracy:",accuracy_score(y_true = y_test, y_pred = y_pred))
# Базовий класифікатор досить добре працює з набором даних, досягаючи 82% точності тестового набору даних із поточними параметрами (результати можуть відрізнятися, якщо у вас немає набору параметрів random_state).

# Створення класифікатора упаковки
# Для пакетування нам потрібно встановити параметр n_estimators, це кількість базових класифікаторів, які наша модель збирається агрегувати разом.
# Для цього зразка набору даних кількість оцінювачів відносно невелика, часто буває, що досліджуються набагато більші діапазони. Налаштування гіперпараметрів зазвичай виконується за допомогою пошуку в сітці , але наразі ми будемо використовувати вибраний набір значень для кількості оцінювачів.
# Починаємо з імпорту необхідної моделі.
from sklearn.ensemble import BaggingClassifier

# Тепер давайте створимо діапазон значень, які представляють кількість оцінювачів, які ми хочемо використовувати в кожному ансамблі.
estimator_range = [2,4,6,8,10,12,14,16]
# Щоб побачити, як класифікатор Bagging працює з різними значеннями n_estimators, нам потрібен спосіб повторювати діапазон значень і зберігати результати з кожного ансамблю. Для цього ми створимо цикл for, зберігаючи моделі та оцінки в окремих списках для подальшої візуалізації.

# Примітка. Параметром за замовчуванням для базового класифікатора BaggingClassifierє , DicisionTreeClassifierтому нам не потрібно встановлювати його під час створення екземпляра моделі упаковки.
models = []
scores = []

for n_estimators in estimator_range:

    # Create bagging classifier
    clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)

    # Fit the model
    clf.fit(X_train, y_train)

    # Append the model and score to their respective list
    models.append(clf)
    scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))
    
# Завдяки збереженим моделям і оцінкам ми тепер можемо візуалізувати покращення продуктивності моделі.
import matplotlib.pyplot as plt

# Generate the plot of scores against number of estimators
plt.figure(figsize=(9,6))
plt.plot(estimator_range, scores)

# Adjust labels and font (to make visable)
plt.xlabel("n_estimators", fontsize = 18)
plt.ylabel("score", fontsize = 18)
plt.tick_params(labelsize = 16)

# Visualize plot
plt.show()
# Пояснення результатів
# Перебираючи різні значення для кількості оцінювачів, ми можемо побачити збільшення продуктивності моделі з 82,2% до 95,5%. Після 14 оцінювачів точність починає падати, знову ж таки, якщо ви встановите інше, random_stateзначення, які ви бачите, відрізнятимуться. Ось чому для забезпечення стабільних результатів найкраще використовувати перехресну перевірку .
# У цьому випадку ми бачимо збільшення точності визначення типу вина на 13,3%.

# Інша форма оцінювання
# Оскільки початкове завантаження вибирає випадкові підмножини спостережень для створення класифікаторів, є спостереження, які залишаються поза участю процесу відбору. Ці спостереження «з мішка» потім можна використовувати для оцінки моделі, подібно до тестового набору. Майте на увазі, що оцінка поза сумкою може переоцінити помилку в проблемах двійкової класифікації, і її слід використовувати лише як доповнення до інших показників.
# Ми побачили в останній вправі, що 12 оцінювачів дали найвищу точність, тому ми використаємо це для створення нашої моделі. Цього разу встановіть для параметра значення oob_scoretrue, щоб оцінити модель за допомогою результатів поза пакетом.
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier

data = datasets.load_wine(as_frame = True)

X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)

oob_model = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)

oob_model.fit(X_train, y_train)

print(oob_model.oob_score_)
# Оскільки зразки, що використовуються в OOB, і тестовий набір відрізняються, а набір даних відносно малий, існує різниця в точності. Рідко, щоб вони були абсолютно однаковими, знову ж таки OOB слід використовувати для швидкого оцінювання помилки, але це не єдиний показник оцінки.

# Створення дерев рішень із класифікатора пакетів
# Як було показано на уроці «Дерево рішень» , можна побудувати графік дерева рішень, створеного моделлю. Також можна побачити окремі дерева рішень, які увійшли до зведеного класифікатора. Це допомагає нам отримати більш інтуїтивне розуміння того, як модель пакетування приходить до своїх прогнозів.

# Примітка: це функціонально лише з меншими наборами даних, де дерева відносно неглибокі та вузькі, що полегшує їх візуалізацію.

# Нам потрібно буде імпортувати plot_treeфункцію з sklearn.tree. Різні дерева можна побудувати на графіку, змінивши оцінювач, який ви бажаєте візуалізувати.

# Створюйте дерева рішень із класифікатора Bagging

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import plot_tree

X = data.data
y = data.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)

clf = BaggingClassifier(n_estimators = 12, oob_score = True,random_state = 22)

clf.fit(X_train, y_train)

plt.figure(figsize=(30, 20))

plot_tree(clf.estimators_[0], feature_names = X.columns)